{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessery stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "m29FF4dPJ7IEQ0ttpTtndB",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this shit aint working, your cuda is probably fucked up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "4CBdmsKnks3EqZ5Aw1NsEa",
     "type": "MD"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"Squares_new_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining NN and creating instance of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "B2JHuXo3IoHBl8P3oIFGjd",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HuiNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HuiNet, self).__init__()\n",
    "        self.layers_indexes = dict()\n",
    "        self.conv_lays = [1, 16]\n",
    "        counter = 0\n",
    "        self.layers_list = []\n",
    "\n",
    "        num_convs = 1\n",
    "        num_fc = 3\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.layers_list.append(torch.nn.Conv2d(in_channels=self.conv_lays[i], out_channels=self.conv_lays[\n",
    "                i + 1], kernel_size=16, padding=8, stride=2))\n",
    "            self.layers_indexes[\"cv\" + str(i + 1)] = counter\n",
    "            counter += 1\n",
    "            self.layers_list.append(torch.nn.ReLU())\n",
    "            self.layers_indexes[\"act\" + str(i + 1)] = counter\n",
    "            counter += 1\n",
    "            self.layers_list.append(torch.nn.MaxPool2d(kernel_size=4, stride=4))\n",
    "            self.layers_indexes[\"pool\" + str(i + 1)] = counter\n",
    "            counter += 1\n",
    "\n",
    "        self.layers_list.append(torch.nn.Linear(16*32*32, 100))\n",
    "        self.layers_indexes['fc1'] = counter\n",
    "        counter += 1\n",
    "        self.layers_list.append(torch.nn.ReLU())\n",
    "        self.layers_indexes[f'act{num_convs + 1}'] = counter\n",
    "        counter += 1\n",
    "    \n",
    "        for i in range(1, num_fc):\n",
    "            if i == num_fc-1:\n",
    "                self.layers_list.append(torch.nn.Linear(100, 5))\n",
    "                self.layers_indexes[f\"fc{i+1}\"] = counter\n",
    "                counter += 1\n",
    "            else:\n",
    "                self.layers_list.append(torch.nn.Linear(100, 100))\n",
    "                self.layers_indexes[f\"fc{i+1}\"] = counter\n",
    "                counter += 1\n",
    "                self.layers_list.append(torch.nn.ReLU())\n",
    "                self.layers_indexes[f\"act{i+num_convs + 2}\"] = counter\n",
    "                counter += 1\n",
    "        self.layers_list = torch.nn.ModuleList(self.layers_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for key in self.layers_indexes:\n",
    "            if key == \"fc1\":\n",
    "                x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "            x = self.layers_list[self.layers_indexes[key]](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "FOLDER_FOR_NETWORKS_EPOCH = \"states_28.08.22_try3\"\n",
    "\n",
    "huinet = HuiNet()\n",
    "\n",
    "start_epoch = 65\n",
    "\n",
    "if start_epoch != 1:\n",
    "    huinet.load_state_dict(torch.load(f\"States/{FOLDER_FOR_NETWORKS_EPOCH}/state{start_epoch-1}.txt\"))\n",
    "    huinet.eval()\n",
    "else:\n",
    "    dictForJson = dict()\n",
    "    for key in huinet.layers_indexes.keys():\n",
    "        dictForJson[key] = str(huinet.layers_list[huinet.layers_indexes[key]])\n",
    "    with open(f\"States/{FOLDER_FOR_NETWORKS_EPOCH}/0_model_description\", \"w\") as outfile:\n",
    "        json.dump(dictForJson, outfile)\n",
    "        \n",
    "huinet.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "VTmywbWtTlSDoeXFMywXhV",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"dist_loss\": 1,\n",
    "    \"size_loss\": 1,\n",
    "    \"angle_loss\": 1\n",
    "}\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "def my_greatest_loss(target, result, params,tensor_board = None, N = -1, print_state=False):\n",
    "    global mse_loss\n",
    "\n",
    "    errs = torch.empty_like(target).to(torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "    errs = target - result\n",
    "    errs /= torch.tensor([255, 255, 255, 255, 180]).to(torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "    # errs = torch.nn.functional.normalize(errs)\n",
    "    loss_dist = (errs[:,0] ** 2 + errs[:,1] ** 2) * params.get(\"dist_loss\")\n",
    "    loss_size = (errs[:,2] **2 + errs[:,3]**2) * params.get(\"size_loss\")\n",
    "    loss_angle = errs[:,4] ** 2 * params.get(\"angle_loss\")\n",
    "    # loss = np.sum(np.linalg.norm(errs.cpu().detach(), axis=0)**2)\n",
    "    if print_state:\n",
    "        print(f\"Distance loss: {torch.mean(loss_dist)} Size loss: {torch.mean(loss_size)} Angle loss: {torch.mean(loss_angle)}\")\n",
    "    loss_ = loss_dist + loss_size + loss_angle\n",
    "    if N != -1:\n",
    "        tensor_board.add_scalar(\"loss_dist\",loss_dist.sum(), N)\n",
    "        tensor_board.add_scalar(\"loss_size\",loss_size.sum(), N)\n",
    "        tensor_board.add_scalar(\"loss_angle\",loss_angle.sum(), N)\n",
    "    del errs\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To GPU if avaliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "9CIXLn1sITrG8bn8JJgVq7",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "huinet = huinet.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "EZGeNvuEpOSaQs5xYOcNDr",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss = my_greatest_loss\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(huinet.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "aQnCp79InIq0lXUgHxjPdQ",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(f\"Datasets/{DATASET_NAME}/labels.txt\")\n",
    "f = f.readlines()\n",
    "N = len(f)\n",
    "print(N)\n",
    "N_test = math.floor(0.98 * N)\n",
    "\n",
    "X_test = torch.zeros((N - N_test, 1, 256, 256))\n",
    "y_test = torch.zeros(N - N_test, 5)\n",
    "\n",
    "for i in range(N_test, N):\n",
    "    name, label = f[i].split()\n",
    "    label = torch.tensor(list(map(int, label.split(\"_\"))))\n",
    "    y_test[i - N_test] += label\n",
    "    img = Image.open(f\"Datasets/{DATASET_NAME}/\" + name)\n",
    "    X_test[i - N_test] += torch.tensor(np.asarray(img)).resize(3, 256, 256)[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing torchision for beatiful graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import product\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning process. Each epoch is saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "cnAgpL8Lz3juoY7QK7BGws",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "N_epochs = 1000\n",
    "\n",
    "test_accuracy_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "tb = SummaryWriter()\n",
    "\n",
    "norm =  torch.tensor([255, 255, 255, 255, 180]).to(torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    order = np.random.permutation(N_test)\n",
    "    current_losses = []\n",
    "    time_start = time.time()\n",
    "    \n",
    "    for start_index in tqdm(range(0, N_test, batch_size),leave=False):\n",
    "        torch.cuda.empty_cache()\n",
    "        X_train = torch.zeros((batch_size,1,256,256))\n",
    "        y_train = torch.zeros((batch_size,5))\n",
    "        for i in range(start_index, start_index + batch_size):\n",
    "            name, label = f[i].split()\n",
    "            label = torch.tensor(list(map(int, label.split(\"_\"))))\n",
    "            y_train[i%batch_size] += label\n",
    "            img = Image.open(f\"Datasets/{DATASET_NAME}/\" + name)\n",
    "            X_train[i%batch_size] += torch.tensor(np.asarray(img)).reshape(3, 256, 256)[0, :]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        X_batch = X_train.to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "\n",
    "        preds = huinet.forward(X_batch)\n",
    "\n",
    "        loss_value = loss(preds/norm, y_batch/norm)\n",
    "        current_losses.append(loss_value.item())\n",
    "        loss_value.backward()\n",
    "        tb.add_scalar(\"Batch\",loss_value.item(), epoch * N_test//batch_size + start_index//batch_size)\n",
    "\n",
    "        optimizer.step()\n",
    "        del X_train, y_train, label\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    test_preds = huinet.forward(X_test)\n",
    "    test_loss_history.append(loss(test_preds/norm, y_test/norm).item())\n",
    "    # # TODO: новая accuracy когда-нибудь\n",
    "    # # accuracy = (test_preds.argmax(dim=0) == y_test).float().mean().data.cpu()\n",
    "    accuracy = np.array(current_losses).mean()\n",
    "    test_accuracy_history.append(accuracy)\n",
    "    print(f\"Epoch: {epoch+start_epoch}/{start_epoch+N_epochs-1} Accuracy: {accuracy} Time:{time.time()-time_start} Last loss: {test_loss_history[-1]}\")\n",
    "    tb.add_scalar(\"Accuracy\",accuracy, epoch)\n",
    "    del test_preds, accuracy\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.save(huinet.state_dict(), f\"States/{FOLDER_FOR_NETWORKS_EPOCH}/state{start_epoch + epoch}.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Function that draws picture with desired epoch of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "VGtVqeBYKuT4rcv8vXlBmB",
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def checkDrawingForEpoche(epoch, drawing, test=True):\n",
    "    huinet = HuiNet()\n",
    "    huinet.float()\n",
    "    huinet.load_state_dict(torch.load(f\"States/{FOLDER_FOR_NETWORKS_EPOCH}/state{epoch}.txt\"))\n",
    "    huinet.eval()\n",
    "    huinet = huinet.to(device)\n",
    "\n",
    "    k = 171\n",
    "    a = huinet.forward(X_test[drawing].reshape(1, 1,256,256)).cpu().detach().numpy().astype(dtype=int).reshape(-1).tolist()  #prediction\n",
    "    b = y_test[drawing].cpu().detach().numpy().astype(dtype=int).tolist()  #label\n",
    "    print(a,b)\n",
    "\n",
    "    #original filled with black color\n",
    "    rect = ((b[0], b[1]), (b[2], b[3]), b[4])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    whiteblankimage = 255 * np.ones(shape=[256, 256, 3], dtype=np.uint8)\n",
    "    cv2.drawContours(whiteblankimage,[box],0,(0,0,0),thickness=cv2.FILLED)\n",
    "\n",
    "    #red contour of prediction\n",
    "    rect = ((a[0], a[1]), (a[2], a[3]), a[4])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(whiteblankimage,[box],0,(255,0,0))\n",
    "\n",
    "    #saving and drawing\n",
    "    # cv2.imwrite(f'ImagesByEpoch/IM2.0/{drawing}_{epoch}.jpeg' , whiteblankimage)\n",
    "    plt.imshow(whiteblankimage)\n",
    "    \n",
    "def checkDrawingsForEpoche(epoch, drawing, base_img = None, test=True, color=(255,0,0)):\n",
    "    huinet = HuiNet()\n",
    "    huinet.float()\n",
    "    huinet.load_state_dict(torch.load(f\"States/{FOLDER_FOR_NETWORKS_EPOCH}/state{epoch}.txt\"))\n",
    "    huinet.eval()\n",
    "    huinet = huinet.to(device)\n",
    "\n",
    "    k = 171\n",
    "    a = huinet.forward(X_test[drawing].reshape(1, 1,256,256)).cpu().detach().numpy().astype(dtype=int).reshape(-1).tolist()  #prediction\n",
    "    b = y_test[drawing].cpu().detach().numpy().astype(dtype=int).tolist()  #label\n",
    "\n",
    "    #original filled with black color\n",
    "    if base_img is None:\n",
    "        whiteblankimage = 255 * np.ones(shape=[256, 256, 3], dtype=np.uint8)\n",
    "    else:\n",
    "        whiteblankimage = base_img\n",
    "\n",
    "    rect = ((b[0], b[1]), (b[2], b[3]), b[4])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(whiteblankimage,[box],0,(0,0,0),thickness=cv2.FILLED)\n",
    "\n",
    "    #red contour of prediction\n",
    "    rect = ((a[0], a[1]), (a[2], a[3]), a[4])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(whiteblankimage,[box],0,color)\n",
    "\n",
    "    #saving and drawing\n",
    "    # cv2.imwrite(f'ImagesByEpoch/IM2.0/{drawing}_{epoch}.jpeg' , whiteblankimage)\n",
    "    return whiteblankimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"... And don't you cry tonight <br>\n",
    "That's a heaven above you, baby...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(300):\n",
    "#     checkDrawingForEpoche(epoch=i, drawing=250)\n",
    "checkDrawingForEpoche(epoch=24, drawing=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, d = 25,1\n",
    "fig, axs = plt.subplots(4,4)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # aa = 0\n",
    "        result = checkDrawingsForEpoche(epoch = 1, drawing=d + i*4 + j)\n",
    "        result = checkDrawingsForEpoche(epoch = e, drawing=d + i*4 + j, base_img=result, color=(0,0,255))\n",
    "        axs[i][j].imshow(result)\n",
    "str_ = str(f\"red - random blue - {e}\")\n",
    "fig.legend(str_, loc='upper center')\n",
    "plt.show()\n",
    "        # total = checkDrawingsForEpoche(epoch = 1, drawing=d + i*4 + j) + checkDrawingsForEpoche(epoch = e, drawing=d + i*4 + j, color=(0,0,255))\n",
    "        # axs[i][j].imshow(checkDrawingsForEpoche(epoch = 1, drawing=d + i*4 + j))\n",
    "        # axs[i][j].plot(checkDrawingsForEpoche(epoch = 1, drawing=d + i*4 + j))\n",
    "        # axs[i][j].imshow(checkDrawingsForEpoche(epoch = 1, drawing=d + i*4 + j))\n",
    "        # axs[i][j].imshow(checkDrawingsForEpoche(epoch = e, drawing=d + i*4 + j, color=(0,0,255)))\n",
    "\n",
    "# fig, axs = plt.subplots(4,4)\n",
    "# for i in range(4):\n",
    "#     for j in range(4):\n",
    "#         axs[i][j].imshow(checkDrawingsForEpoche(epoch = 1, drawing=d + i*4 + j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = y_test[3].cpu().detach().numpy().astype(dtype=int).tolist()\n",
    "# rect = ((b[0], b[1]), (b[2], b[3]), b[4])\n",
    "# box = cv2.boxPoints(rect)\n",
    "# box = np.int0(box)\n",
    "# whiteblankimage = 255 * np.ones(shape=[256, 256, 3], dtype=np.uint8)\n",
    "# cv2.drawContours(whiteblankimage,[box],0,(0,0,0),thickness=cv2.FILLED)\n",
    "huinet = HuiNet()\n",
    "huinet.float()\n",
    "huinet.load_state_dict(torch.load(f\"states_3.1.1/state{54}.txt\"))\n",
    "huinet.eval()\n",
    "huinet = huinet.to(device)\n",
    "whitenoise = torch.tensor(np.random.randint(0,255,(256,256)),dtype=torch.float32)\n",
    "whitenoise = whitenoise.to(device)\n",
    "\n",
    "huinet.layers_list[0].reset_parameters()\n",
    "\n",
    "im =  huinet.layers_list[0](whitenoise.reshape(1, 1,256,256)).cpu().detach().numpy().astype(dtype=int).reshape(16,129,129)\n",
    "# im = huinet.layers_list[1](im)\n",
    "# im = huinet.layers_list[2](im)\n",
    "# plt.imshow(im[7])\n",
    "# print(im[5])\n",
    "\n",
    "fig, axs = plt.subplots(4,4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i][j].imshow(im[i*4+j],cmap=\"gray\",vmin=0,vmax=255)\n",
    "        axs[i][j].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(whitenoise.cpu().numpy(),cmap=\"gray\", vmin=0,vmax=255)"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "torchsummary",
     "source": "PIP"
    }
   ],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
